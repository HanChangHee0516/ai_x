{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1a1281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:100% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:20pt;}\n",
       "div.text_cell_render.rendered_html{font-size:18pt;}\n",
       "div.text_cell_render.rendered_html{font-size:15pt;}\n",
       "div.output {font-size:18pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:18pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:18pt;padding:5px;}\n",
       "table.dataframe{font-size:18px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:100% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:20pt;}\n",
    "div.text_cell_render.rendered_html{font-size:18pt;}\n",
    "div.text_cell_render.rendered_html{font-size:15pt;}\n",
    "div.output {font-size:18pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:18pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:18pt;padding:5px;}\n",
    "table.dataframe{font-size:18px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6046a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f3ac6c",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">ch1. 허깅페이스</span>\n",
    "- Transformers라이브러리 내 pipeline()함수\n",
    "- Inference API : key를 사용\n",
    "# 1. 텍스트 기반 감정분석(긍정/부정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddcdaedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1ba0641bb347d9bb2ecae91769b995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fa3c1716bd45d58e521cc8b177770c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acaee01a1904655ba9a65e015640cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf850890690a4e0697eaa57dfaea6cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(task=\"text-classification\",\n",
    "                     model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad7d72ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8940554261207581}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"이 영화는 정말 최고였어요. 감동적이고 연기가 대단해요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "826f3b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POSITIVE', 'NEGATIVE']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = classifier([\"I've been waiting for a HuggingFace course my whole life.\",\n",
    "            \"I hate this so much!\"])\n",
    "[r.get('label')   for r in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c977fe7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task=\"sentiment-analysis\",\n",
    "                     model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "classifier([\"I've been waiting for a HuggingFace course my whole life.\",\n",
    "            \"I hate this so much!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdaa1f5",
   "metadata": {},
   "source": [
    "# 2. 제로-샷 분류(zero-shot-classification)\n",
    "- 비지도학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba599152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26747944e1c46f2a619dedf6da1f66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\901-00\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\901-00\\.cache\\huggingface\\hub\\models--facebook--bart-large-mnli. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0903c85fe64f5d9aea18de48d7e803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e075439014654ef9bf8593b79518aabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901f5e695c3b4dd58b72a3467b1e17f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcccdc67dab64afc98b118525ede5d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!',\n",
       " 'labels': ['urgent', 'phone', 'computer', 'tablet'],\n",
       " 'scores': [0.5049763917922974,\n",
       "  0.48007503151893616,\n",
       "  0.012633666396141052,\n",
       "  0.0023148944601416588]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                     \"facebook/bart-large-mnli\")\n",
    "classifier(\"I have a problem with my iphone that needs to be resolved asap!!\",\n",
    "          candidate_labels=[\"phone\", \"urgent\", \"tablet\", \"computer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39720c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the transformers library.',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.9053581357002258, 0.07259627431631088, 0.02204558439552784]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 제시된 문장이 어떤 분류에 속할지 \n",
    "classifier(\n",
    "    \"This is a course about the transformers library.\",\n",
    "    candidate_labels=[\"education\", \"business\", \"politics\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf06c6f",
   "metadata": {},
   "source": [
    "# 3. text 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a87db047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"In this course. We will teach you how to build your own system, and how to create a decentralized blockchain on your own. Don't worry, it's a first step.\\n\\nIt's not about a simple program or a simple program to create a decentralized system. It's about a system that has been built and maintained and validated. It's about using your blockchain for your smart contract to make and maintain your own smart contract. We'll be teaching you about how to build and maintain your own smart contract. We will be building and maintaining your smart contract with your blockchain.\\n\\nYou'll learn the fundamentals of the smart contract and how you can get started. We'll teach you how to create an account, create a new account, and change your current account. We'll provide you with a basic understanding of the financial and technical aspects of the smart contract.\\n\\nWe'll be building a system that allows you to do business with the blockchain and have decentralized applications.\\n\\nYou'll learn how to create and maintain a business account on your own smart contract. You'll get a basic understanding of the financial and technical aspects of the smart contract. We'll show you how to create a business account on your own smart contract. You'll get a basic understanding of the financial and technical aspects of the smart contract.\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(task=\"text-generation\",\n",
    "                    model=\"gpt2\") # 허깅페이스에는 gpt2까지\n",
    "generator(\"In this course. We will teach you how to\",\n",
    "         pad_token_id=generator.tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeecde32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '이 과정은 다음과 같은 방법을 알려드려요. 통았 자니다. 알려드려요 (오 자합니다. 보이으요 합니다. 알려드려요 합니다. 통았 자니다. 알려드려요 (오 자보으요 합니다. 보이으요 합니다. 통았 자니다. 알려드려요 (오 자보으요 합니다. 보이으요 합니다. 알려드려요 (오 자보'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"이 과정은 다음과 같은 방법을 알려드려요. \",\n",
    "         pad_token_id=generator.tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a2d34c",
   "metadata": {},
   "source": [
    "# 4. 마스크 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18289be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9cf6bedc4543b08a19fa42dec9aec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\901-00\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\901-00\\.cache\\huggingface\\hub\\models--distilroberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f06dc762354b07ade0f0a61427c62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d056da582c24c8eb8f60baa426d1f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a680b3dfb4c446368ee406c6c77c9e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ebfd62173d476489e7369ab7b6bd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2267cbf3b24da6b49303267056c9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.19275875389575958,\n",
       "  'token': 3299,\n",
       "  'token_str': ' doctor',\n",
       "  'sequence': \"I'm going to hospital and meet a doctor\"},\n",
       " {'score': 0.06794668734073639,\n",
       "  'token': 27321,\n",
       "  'token_str': ' psychiatrist',\n",
       "  'sequence': \"I'm going to hospital and meet a psychiatrist\"},\n",
       " {'score': 0.06435622274875641,\n",
       "  'token': 16308,\n",
       "  'token_str': ' surgeon',\n",
       "  'sequence': \"I'm going to hospital and meet a surgeon\"},\n",
       " {'score': 0.05912911519408226,\n",
       "  'token': 9008,\n",
       "  'token_str': ' nurse',\n",
       "  'sequence': \"I'm going to hospital and meet a nurse\"},\n",
       " {'score': 0.05705659091472626,\n",
       "  'token': 1441,\n",
       "  'token_str': ' friend',\n",
       "  'sequence': \"I'm going to hospital and meet a friend\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\", \"distilroberta-base\")\n",
    "unmasker(\"I'm going to hospital and meet a <mask>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "950d65a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.0361194983124733,\n",
       "  'token': 265,\n",
       "  'token_str': ' business',\n",
       "  'sequence': \"Hello, I'm a business model\"},\n",
       " {'score': 0.02683814987540245,\n",
       "  'token': 18150,\n",
       "  'token_str': ' freelance',\n",
       "  'sequence': \"Hello, I'm a freelance model\"}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Hello, I'm a <mask> model\",\n",
    "        top_k=2) #top_k를 안 주면 5개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b30607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.06705890595912933,\n",
       "  'token': 4827,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': \"hello, i ' m a fashion model\"},\n",
       " {'score': 0.058972738683223724,\n",
       "  'token': 2047,\n",
       "  'token_str': 'new',\n",
       "  'sequence': \"hello, i ' m a new model\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# google-bert/bert-base-uncased사용을 위해 key 발부\n",
    "from transformers import pipeline\n",
    "unmasker = pipeline(task=\"fill-mask\",\n",
    "                   model=\"google-bert/bert-base-uncased\")\n",
    "unmasker(\"Hello, I'm a [MASK] model\", top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ba6c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "#print(os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8037c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "client = InferenceClient(provider=\"hf-inference\",\n",
    "                        api_key=os.environ['HF_TOKEN'])\n",
    "result = client.fill_mask(\n",
    "    \"Hello, I'm a [MASK] model\",\n",
    "    model = \"google-bert/bert-base-uncased\",\n",
    "    top_k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99626036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"hello, i ' m a fashion model\", \"hello, i ' m a new model\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r.sequence for r in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a3d10b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline(task=\"fill-mask\",\n",
    "                   model=\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "086967b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.14155958592891693,\n",
       "  'token': 62592,\n",
       "  'token_str': '여자',\n",
       "  'sequence': '안녕하세요? 나는 여자 모델입니다'},\n",
       " {'score': 0.13301970064640045,\n",
       "  'token': 108399,\n",
       "  'token_str': '가수',\n",
       "  'sequence': '안녕하세요? 나는 가수 모델입니다'},\n",
       " {'score': 0.08411936461925507,\n",
       "  'token': 102574,\n",
       "  'token_str': '프로',\n",
       "  'sequence': '안녕하세요? 나는 프로 모델입니다'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"안녕하세요? 나는 [MASK] 모델입니다\", top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b390fd81",
   "metadata": {},
   "source": [
    "# 5. 개체명 인식(NER : Named Entity REcognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34630d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(task=\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcac18bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-PER',\n",
       "  'score': 0.9987527,\n",
       "  'index': 4,\n",
       "  'word': 'Tom',\n",
       "  'start': 11,\n",
       "  'end': 14},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9977857,\n",
       "  'index': 9,\n",
       "  'word': 'Facebook',\n",
       "  'start': 29,\n",
       "  'end': 37},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9946062,\n",
       "  'index': 11,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 41,\n",
       "  'end': 49}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"My name is Tom and I work at Facebook in Brooklyn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f625a3c2",
   "metadata": {},
   "source": [
    "# 6. 질의 응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24fad744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "question_answer = pipeline(\"question-answering\",\n",
    "                          \"distilbert-base-cased-distilled-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "481f3aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.5976610779762268, 'start': 29, 'end': 37, 'answer': 'Facebook'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Tom and I work at Facebook in Brooklyn\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d3bd760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Facebook'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context=\"My name is Tom and I work at Facebook in Brooklyn\"\n",
    "context[29:37]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f42654",
   "metadata": {},
   "source": [
    "# 7. 문서요약\n",
    "- 현재 torch 2.6이상 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebe1c2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c9e36b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(task=\"summarization\",\n",
    "                     model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed0c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer(\"\"\"It is a momentous occasion for fans of the K-pop group BTS. The seven singers of the popular K-pop band plan to reunite as a group sometime in 2025 now that they’ve finished their service.\n",
    "Last week, BTS superstars RM and V were discharged from South Korea’s military after fulfilling their mandatory service. Jimin and Jung Kook were discharged a day later. All four were enlisted in December 2023.\n",
    "K-pop supergroup BTS could soon make a comeback with six out of its seven members discharged from South Korea’s military\n",
    "Six of the group’s seven members served in the army, while Suga fulfilled his duty as a social service agent, an alternative form of military service.\n",
    "Jin, the oldest BTS member, was discharged in June 2024. J-Hope was discharged in October.\n",
    "In South Korea, all able-bodied men aged 18 to 28 are required by law to perform 18-21 months of military service under a conscription system meant to deter aggression from rival North Korea.\n",
    "The law gives special exemptions to athletes, classical and traditional musicians, and ballet and other dancers if they have obtained top prizes in certain competitions and are assessed to have enhanced national prestige. K-pop stars and other entertainers aren’t subject to such privileges.\n",
    "However, in 2020, BTS postponed their service until age 30 after South Korea’s National Assembly revised its Military Service Act, allowing K-pop stars to delay their enlistment until age 30.\n",
    "There was heated public debate in 2022 over whether to offer special exemptions of mandatory military service for BTS members, \n",
    "until the group’s management agency announced in October 2022 that all seven members would fulfill their duties.\"\"\",\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4201f7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9294c6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b175cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c47829e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56328f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534e070b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
